use crate::metadata::BenchmarkCrate;
use std::path::Path;

/// Generate runner.rs source code
///
/// Creates a Rust program that:
/// 1. Declares extern crate for all benchmark crates
/// 2. Uses inventory to collect all benchmarks
/// 3. Runs each benchmark and displays results
pub fn generate_runner(benchmark_crates: &[BenchmarkCrate]) -> String {
    let mut code = String::new();

    // Add header comment
    code.push_str("// Generated by cargo-simplebench\n");
    code.push_str("// This runner collects and executes all benchmarks from the workspace\n\n");

    // Add extern declarations for runtime crates
    code.push_str("extern crate simplebench_runtime;\n");
    code.push_str("extern crate inventory;\n\n");

    // Add extern declarations for all benchmark crates
    for crate_info in benchmark_crates {
        let crate_name = crate_info.name.replace('-', "_");
        code.push_str(&format!("extern crate {};\n", crate_name));
    }

    code.push('\n');

    // Add main function
    code.push_str("fn main() {\n");
    code.push_str("    use simplebench_runtime::{\n");
    code.push_str("        run_and_stream_benchmarks,\n");
    code.push_str("        BenchmarkConfig,\n");
    code.push_str("        process_with_baselines,\n");
    code.push_str("        check_regressions_and_exit,\n");
    code.push_str("    };\n\n");

    code.push_str("    // Change to workspace root for baseline storage\n");
    code.push_str(
        "    if let Ok(workspace_root) = std::env::var(\"SIMPLEBENCH_WORKSPACE_ROOT\") {\n",
    );
    code.push_str("        if let Err(e) = std::env::set_current_dir(&workspace_root) {\n");
    code.push_str("            eprintln!(\"Failed to change to workspace root: {}\", e);\n");
    code.push_str("            std::process::exit(1);\n");
    code.push_str("        }\n");
    code.push_str("    }\n\n");

    code.push_str("    // Load configuration (file + env overrides)\n");
    code.push_str("    let config = BenchmarkConfig::load();\n\n");

    code.push_str("    // Run all benchmarks with streaming output\n");
    code.push_str("    let results = run_and_stream_benchmarks(&config);\n\n");

    code.push_str("    if results.is_empty() {\n");
    code.push_str("        eprintln!(\"ERROR: No benchmarks found!\");\n");
    code.push_str("        eprintln!(\"Make sure your benchmark functions are marked with #[simplebench]\");\n");
    code.push_str("        std::process::exit(1);\n");
    code.push_str("    }\n\n");

    code.push_str("    // Check for regressions and exit if in CI mode\n");
    code.push_str("    // Note: comparisons are handled inside run_and_stream_benchmarks\n");
    code.push_str("    if config.comparison.ci_mode {\n");
    code.push_str("        // Re-check baselines for CI exit code\n");
    code.push_str(
        "        if let Ok(comparisons) = process_with_baselines(&results, &config.comparison) {\n",
    );
    code.push_str("            check_regressions_and_exit(&comparisons, &config.comparison);\n");
    code.push_str("        }\n");
    code.push_str("    }\n");
    code.push_str("}\n");

    code
}

/// Write runner.rs to a file
pub fn write_runner(
    target_dir: &Path,
    benchmark_crates: &[BenchmarkCrate],
) -> Result<std::path::PathBuf, std::io::Error> {
    let runner_code = generate_runner(benchmark_crates);
    let runner_path = target_dir.join("simplebench_runner.rs");
    std::fs::write(&runner_path, runner_code)?;
    Ok(runner_path)
}
